{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "PyTorch Tensor Examples",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lewislou/Pytorch-pratical-Learning/blob/master/PyTorch_Tensor_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r_ybX-tBEvY",
        "colab_type": "text"
      },
      "source": [
        "# Some PyTorch Tensor operation examples\n",
        "\n",
        "Firstly, creation of Tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXtKAsUwAvm2",
        "colab_type": "code",
        "outputId": "e9ad941a-c5e5-4c55-b20d-d6e9ae805809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# create an empty floating point tensor\n",
        "x = torch.empty(1, 3)\n",
        "print(x)\n",
        "\n",
        "# Creation of default floating point tensor (float32) filled with ones\n",
        "y = torch.ones(2,5)\n",
        "\n",
        "# Creation of Integer tensor from existing data; The bad way (because you've _explicitly_ created a CPU-backed Tensor)\n",
        "zbad = torch.IntTensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(zbad)\n",
        "\n",
        "# Creation of Integer tensor from existing data; The good way (this way allows you to specify device=... so it could be backed by the GPU)\n",
        "z = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float)\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.1143e-35, 0.0000e+00, 4.4842e-44]])\n",
            "torch.float32\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNOsZ4DvBAUy",
        "colab_type": "text"
      },
      "source": [
        "Inspecting a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZGG-K1TAvm-",
        "colab_type": "code",
        "outputId": "3284dead-69dd-4b0a-c31c-26730da5d7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x.size())\n",
        "print(x.shape) #usually used in preference to size()\n",
        "\n",
        "print(z.type()) # the underlying class; this will be dependent on the backing device (so there are different FloatTensor implementations for different devices)\n",
        "print(z.device) # the actual backing device (which isn't just cpu/gpu, but could tell you which gpu...)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3])\n",
            "torch.Size([1, 3])\n",
            "torch.FloatTensor\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM9cD8v-GCsK",
        "colab_type": "text"
      },
      "source": [
        "Setting values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tJstUUaAvnD",
        "colab_type": "code",
        "outputId": "4b7bbbe9-1963-41e7-a49d-99ff08d37ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x[0,0] = 0 #setting a specific value\n",
        "print(x)\n",
        "\n",
        "x[0,1:2] = 0 #setting a range of values (the slice operator : works just like in numpy)\n",
        "print(x)\n",
        "\n",
        "# Setting all  the values. Note all in-place operations are suffixed with an underscore\n",
        "x.fill_(1.125)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0000, 0.0000, 1.1250]])\n",
            "tensor([[0.0000, 0.0000, 1.1250]])\n",
            "tensor([[1.1250, 1.1250, 1.1250]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL7uObp2Gqqx",
        "colab_type": "text"
      },
      "source": [
        "1st-order statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGpUpvcnAvnI",
        "colab_type": "code",
        "outputId": "198ec1dc-4f4a-429c-8e81-c2311e9305a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.mean())\n",
        "print(x.std())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.1250)\n",
            "tensor(0.)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3750)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifxQZtMVG64j",
        "colab_type": "text"
      },
      "source": [
        "Note that the return type of these operations is a 0d Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC5o5nxOG4V6",
        "colab_type": "code",
        "outputId": "2f0a79ab-fa06-46df-d7dc-ce98c0fdcaba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x.sum().shape)\n",
        "x.sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3750)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7RL0Zj7HLhD",
        "colab_type": "text"
      },
      "source": [
        "To get this back to a Python number:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPlWse_mAvnP",
        "colab_type": "code",
        "outputId": "87f32158-2be1-4e1e-e1b2-b8250835cacc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## 0d tensor can be converted back to a Python scalar with item()\n",
        "x.sum().item()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVksTK-MHqtK",
        "colab_type": "text"
      },
      "source": [
        "You can also go straight to a numpy array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXQqXugOAvnT",
        "colab_type": "code",
        "outputId": "4c4cfa56-dcef-4aae-eeff-3127052c7c24",
        "colab": {}
      },
      "source": [
        "z.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6SQfF3lIuHB",
        "colab_type": "text"
      },
      "source": [
        "Note in both cases above, if the Tensor is not already on the CPU, you have to copy it there first otherwise you'll get an error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KtFLvvUI5I3",
        "colab_type": "code",
        "outputId": "7882a5fd-9022-47a7-bae4-011821df1fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(z.cpu().numpy())\n",
        "print(z[0,0].item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xgCRzGNJzxQ",
        "colab_type": "text"
      },
      "source": [
        "Element-wise operations are easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmKXTNZsAvnw",
        "colab_type": "code",
        "outputId": "10bd4537-d8e8-41cb-eb67-1a611340880a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "x = torch.tensor([ 10., 20., 30.])\n",
        "y = torch.tensor([ 11., 21., 31.])\n",
        "\n",
        "print(x + y) #Tensor-Tensor addition (element-wise addition)\n",
        "print(x - y) #Tensor-Tensor subtraction (element-wise subtraction)\n",
        "print(x * y) #Hadamard product of two tensors\n",
        "print(x / y) #Hadamard division of two tensors\n",
        "print(x**2) #raising to a power\n",
        "print(torch.sin(x)) #applying sin element-wise\n",
        "print(x == 10) #element-wise boolean tests\n",
        "print(x <= 20) #element-wise boolean tests\n",
        "print((x <= 20) & (x==10)) #element-wise logical `and`"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([21., 41., 61.])\n",
            "tensor([21., 41., 61.])\n",
            "tensor([110., 420., 930.])\n",
            "tensor([0.9091, 0.9524, 0.9677])\n",
            "tensor([100., 400., 900.])\n",
            "tensor([-0.5440,  0.9129, -0.9880])\n",
            "tensor([ True, False, False])\n",
            "tensor([ True,  True, False])\n",
            "tensor([ True, False, False])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8t2E5piL0Wu",
        "colab_type": "text"
      },
      "source": [
        "Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-ES1RckAvnz",
        "colab_type": "code",
        "outputId": "691ebe48-145b-4c28-991e-c5d3123edfe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = torch.tensor([ 10., 20., 30.]) #x is a 1d tensor\n",
        "m = torch.tensor([[ 0., 0., 1. ],[ 0., 2., 0. ],[ 3., 0., 0. ]]) #m is a 2d tensor\n",
        "\n",
        "try:\n",
        "  print(torch.mm(m,x) #torch.mm performs matrix-matrix multiplication; this will fail because .mm doesn't support broadcasting and the inputs have differing tensor order\n",
        "except Exception as e:\n",
        "  print(\"Error: \" + str(e))\n",
        "print(torch.matmul(m,x)) #torch.matmul performs matrix-matrix multiplication with broadcasting; it will automatically convert x to a 2d tensor so the multiplication can be performed\n",
        "print(m @ x) #ampersand is convienent short-hand notation for matmul\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
            "tensor([30., 40., 30.])\n",
            "tensor([30., 40., 30.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhSwen88NnvG",
        "colab_type": "text"
      },
      "source": [
        "Unsqueezing tensors - this is something you'll probably see a lot; unsqueezing  adds another dimension:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX5TaPmeAvn2",
        "colab_type": "code",
        "outputId": "b7c278d9-9f4f-4c44-dcfb-556207ddd3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "x = torch.tensor([ 10., 20., 30.])\n",
        "print(x.shape)\n",
        "x.unsqueeze_(-1) #in-place unsqueeze, adding the new dimension in the last position (so we create a _column_ vector)\n",
        "print(x.shape)\n",
        "\n",
        "print(x.t().shape) #note .t() transposes a tensor\n",
        "\n",
        "print(torch.mm(m,x)) #  the previous .mm that failed because of mismatched sizes will now work"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3])\n",
            "torch.Size([3, 1])\n",
            "torch.Size([1, 3])\n",
            "tensor([[30.],\n",
            "        [40.],\n",
            "        [30.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KLIXGL8NsoH",
        "colab_type": "text"
      },
      "source": [
        "Sometimes we'll need to reshape tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r-PHr5CAvn5",
        "colab_type": "code",
        "outputId": "0006df7a-389a-4738-80e4-01d289d75f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x2 = x.reshape(3) # back to where we started!\n",
        "print(x2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10., 20., 30.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrbtLkJOXndQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}